{
  "RL-Tuned Models": {
    "models": [
      {
        "size": "7B",
        "rl_tuned": true,
        "family": "Nemotron",
        "model_name": "nvidia/AceReason-Nemotron-7B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 128.19,
            "avg_tokens_saved_without_context": 1738.21,
            "avg_percentage_saved_with_context": 2.1919316543411607,
            "avg_percentage_saved_without_context": 39.84081214477192,
            "early_stopping_rate_with_context": 3.0,
            "early_stopping_rate_without_context": 73.0,
            "accuracy_dropped_with_context": 3.0,
            "abstention_increased_without_context": 24.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 43.88059701492537,
            "avg_tokens_saved_without_context": 3931.0746268656717,
            "avg_percentage_saved_with_context": 1.0861533914585488,
            "avg_percentage_saved_without_context": 58.4725405019467,
            "early_stopping_rate_with_context": 1.4925373134328357,
            "early_stopping_rate_without_context": 83.5820895522388,
            "accuracy_dropped_with_context": 1.4925373134328357,
            "abstention_increased_without_context": 62.68656716417911
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 431.8,
            "avg_tokens_saved_without_context": 773.35,
            "avg_percentage_saved_with_context": 4.260063141278611,
            "avg_percentage_saved_without_context": 14.241276522353024,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 20.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 15.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 138.56521739130434,
            "avg_tokens_saved_without_context": 104.72463768115942,
            "avg_percentage_saved_with_context": 4.400879123731289,
            "avg_percentage_saved_without_context": 3.25652244192892,
            "early_stopping_rate_with_context": 10.144927536231885,
            "early_stopping_rate_without_context": 8.695652173913043,
            "accuracy_dropped_with_context": 2.898550724637681,
            "abstention_increased_without_context": 8.695652173913043
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 77.54,
            "avg_tokens_saved_without_context": 240.72,
            "avg_percentage_saved_with_context": 2.1340237919300695,
            "avg_percentage_saved_without_context": 3.429948540520036,
            "early_stopping_rate_with_context": 4.0,
            "early_stopping_rate_without_context": 9.0,
            "accuracy_dropped_with_context": 1.0,
            "abstention_increased_without_context": 9.0
          }
        }
      },
      {
        "size": "7B",
        "rl_tuned": true,
        "family": "Nemotron",
        "model_name": "nvidia/AceReason-Nemotron-1.1-7B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 228.12,
            "avg_tokens_saved_without_context": 2034.6,
            "avg_percentage_saved_with_context": 3.1763433110923525,
            "avg_percentage_saved_without_context": 47.379025077690024,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 94.0,
            "accuracy_dropped_with_context": 3.0,
            "abstention_increased_without_context": 61.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 222.50746268656715,
            "avg_tokens_saved_without_context": 3950.492537313433,
            "avg_percentage_saved_with_context": 4.03129686139667,
            "avg_percentage_saved_without_context": 57.26185675425777,
            "early_stopping_rate_with_context": 8.955223880597014,
            "early_stopping_rate_without_context": 83.5820895522388,
            "accuracy_dropped_with_context": 8.955223880597014,
            "abstention_increased_without_context": 61.19402985074627
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 1851.35,
            "avg_tokens_saved_without_context": 3075.8,
            "avg_percentage_saved_with_context": 16.91316820074841,
            "avg_percentage_saved_without_context": 44.25957810125601,
            "early_stopping_rate_with_context": 20.0,
            "early_stopping_rate_without_context": 70.0,
            "accuracy_dropped_with_context": 5.0,
            "abstention_increased_without_context": 55.00000000000001
          },
          "icraft": {
            "avg_tokens_saved_with_context": 140.34782608695653,
            "avg_tokens_saved_without_context": 297.2463768115942,
            "avg_percentage_saved_with_context": 3.2137013112909614,
            "avg_percentage_saved_without_context": 7.774127637402203,
            "early_stopping_rate_with_context": 5.797101449275362,
            "early_stopping_rate_without_context": 14.492753623188406,
            "accuracy_dropped_with_context": 4.3478260869565215,
            "abstention_increased_without_context": 11.594202898550725
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 119.46,
            "avg_tokens_saved_without_context": 273.72,
            "avg_percentage_saved_with_context": 2.46575936775206,
            "avg_percentage_saved_without_context": 6.653119218230433,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 16.0,
            "accuracy_dropped_with_context": 2.0,
            "abstention_increased_without_context": 15.0
          }
        }
      },
      {
        "size": "7B",
        "rl_tuned": true,
        "family": "MiMo",
        "model_name": "XiaomiMiMo/MiMo-7B-RL-0530",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 196.89,
            "avg_tokens_saved_without_context": 3466.04,
            "avg_percentage_saved_with_context": 3.6574946227631977,
            "avg_percentage_saved_without_context": 62.11733456265234,
            "early_stopping_rate_with_context": 7.000000000000001,
            "early_stopping_rate_without_context": 98.0,
            "accuracy_dropped_with_context": 7.000000000000001,
            "abstention_increased_without_context": 18.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 234.88059701492537,
            "avg_tokens_saved_without_context": 7573.835820895522,
            "avg_percentage_saved_with_context": 3.017936366224455,
            "avg_percentage_saved_without_context": 68.15771113118006,
            "early_stopping_rate_with_context": 4.477611940298507,
            "early_stopping_rate_without_context": 83.5820895522388,
            "accuracy_dropped_with_context": 4.477611940298507,
            "abstention_increased_without_context": 35.82089552238806
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 742.25,
            "avg_tokens_saved_without_context": 1591.3,
            "avg_percentage_saved_with_context": 4.541144080758642,
            "avg_percentage_saved_without_context": 16.822616751378515,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 25.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 20.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 497.5507246376812,
            "avg_tokens_saved_without_context": 1115.7826086956522,
            "avg_percentage_saved_with_context": 9.674672768378246,
            "avg_percentage_saved_without_context": 18.47133352569615,
            "early_stopping_rate_with_context": 18.84057971014493,
            "early_stopping_rate_without_context": 27.536231884057973,
            "accuracy_dropped_with_context": 5.797101449275362,
            "abstention_increased_without_context": 26.08695652173913
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 1332.53,
            "avg_tokens_saved_without_context": 1550.53,
            "avg_percentage_saved_with_context": 16.61891922231968,
            "avg_percentage_saved_without_context": 21.771542410670655,
            "early_stopping_rate_with_context": 23.0,
            "early_stopping_rate_without_context": 35.0,
            "accuracy_dropped_with_context": 11.0,
            "abstention_increased_without_context": 28.000000000000004
          }
        }
      },
      {
        "size": "7B",
        "rl_tuned": true,
        "family": "Skywork",
        "model_name": "Skywork/Skywork-OR1-7B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 534.88,
            "avg_tokens_saved_without_context": 4053.98,
            "avg_percentage_saved_with_context": 6.0286099600678025,
            "avg_percentage_saved_without_context": 44.88479877434591,
            "early_stopping_rate_with_context": 9.0,
            "early_stopping_rate_without_context": 73.0,
            "accuracy_dropped_with_context": 7.000000000000001,
            "abstention_increased_without_context": 35.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 125.01492537313433,
            "avg_tokens_saved_without_context": 6415.611940298508,
            "avg_percentage_saved_with_context": 2.2957487792922793,
            "avg_percentage_saved_without_context": 56.94192635074796,
            "early_stopping_rate_with_context": 4.477611940298507,
            "early_stopping_rate_without_context": 74.6268656716418,
            "accuracy_dropped_with_context": 4.477611940298507,
            "abstention_increased_without_context": 55.223880597014926
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 259.4,
            "avg_tokens_saved_without_context": 2277.3,
            "avg_percentage_saved_with_context": 3.8785885167464116,
            "avg_percentage_saved_without_context": 12.942402919337137,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 15.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 15.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 85.4927536231884,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 2.579450293817514,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 8.695652173913043,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 7.246376811594203
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 99.5,
            "avg_tokens_saved_without_context": 58.26,
            "avg_percentage_saved_with_context": 2.8184368935333293,
            "avg_percentage_saved_without_context": 2.2621550363986462,
            "early_stopping_rate_with_context": 8.0,
            "early_stopping_rate_without_context": 9.0,
            "accuracy_dropped_with_context": 4.0,
            "abstention_increased_without_context": 7.000000000000001
          }
        }
      },
      {
        "size": "14B",
        "rl_tuned": true,
        "family": "Phi",
        "model_name": "microsoft/Phi-4-reasoning-plus",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 7552.11,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 78.37777381846881,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 100.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 28.999999999999996
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 591.2089552238806,
            "avg_tokens_saved_without_context": 10112.34328358209,
            "avg_percentage_saved_with_context": 3.78426685158128,
            "avg_percentage_saved_without_context": 69.86439446784186,
            "early_stopping_rate_with_context": 4.477611940298507,
            "early_stopping_rate_without_context": 88.05970149253731,
            "accuracy_dropped_with_context": 2.9850746268656714,
            "abstention_increased_without_context": 32.83582089552239
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 5616.75,
            "avg_tokens_saved_without_context": 11762.0,
            "avg_percentage_saved_with_context": 32.95680413614406,
            "avg_percentage_saved_without_context": 71.3150067811716,
            "early_stopping_rate_with_context": 40.0,
            "early_stopping_rate_without_context": 85.0,
            "accuracy_dropped_with_context": 10.0,
            "abstention_increased_without_context": 55.00000000000001
          },
          "icraft": {
            "avg_tokens_saved_with_context": 311.2608695652174,
            "avg_tokens_saved_without_context": 588.6376811594203,
            "avg_percentage_saved_with_context": 4.95289441783734,
            "avg_percentage_saved_without_context": 8.882560860309733,
            "early_stopping_rate_with_context": 7.246376811594203,
            "early_stopping_rate_without_context": 11.594202898550725,
            "accuracy_dropped_with_context": 5.797101449275362,
            "abstention_increased_without_context": 10.144927536231885
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 325.54,
            "avg_tokens_saved_without_context": 2234.74,
            "avg_percentage_saved_with_context": 4.843559210246152,
            "avg_percentage_saved_without_context": 28.005993722373265,
            "early_stopping_rate_with_context": 8.0,
            "early_stopping_rate_without_context": 41.0,
            "accuracy_dropped_with_context": 4.0,
            "abstention_increased_without_context": 39.0
          }
        }
      },
      {
        "size": "14B",
        "rl_tuned": true,
        "family": "Nemotron",
        "model_name": "nvidia/AceReason-Nemotron-14B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 134.085,
            "avg_tokens_saved_without_context": 2212.515,
            "avg_percentage_saved_with_context": 1.8048040071380427,
            "avg_percentage_saved_without_context": 47.208865603726174,
            "early_stopping_rate_with_context": 4.5,
            "early_stopping_rate_without_context": 86.5,
            "accuracy_dropped_with_context": 3.5000000000000004,
            "abstention_increased_without_context": 32.5
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 124.65671641791045,
            "avg_tokens_saved_without_context": 4083.2985074626868,
            "avg_percentage_saved_with_context": 3.1382853193103077,
            "avg_percentage_saved_without_context": 54.769132996993285,
            "early_stopping_rate_with_context": 5.970149253731343,
            "early_stopping_rate_without_context": 80.59701492537313,
            "accuracy_dropped_with_context": 5.970149253731343,
            "abstention_increased_without_context": 53.73134328358209
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 954.325,
            "avg_tokens_saved_without_context": 1266.225,
            "avg_percentage_saved_with_context": 11.771137041224558,
            "avg_percentage_saved_without_context": 21.170450663671534,
            "early_stopping_rate_with_context": 17.5,
            "early_stopping_rate_without_context": 32.5,
            "accuracy_dropped_with_context": 10.0,
            "abstention_increased_without_context": 25.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 68.91304347826087,
            "avg_tokens_saved_without_context": 148.3913043478261,
            "avg_percentage_saved_with_context": 2.3788067050857995,
            "avg_percentage_saved_without_context": 4.953151154797078,
            "early_stopping_rate_with_context": 7.246376811594203,
            "early_stopping_rate_without_context": 13.043478260869565,
            "accuracy_dropped_with_context": 5.797101449275362,
            "abstention_increased_without_context": 13.043478260869565
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 162.35,
            "avg_tokens_saved_without_context": 220.44,
            "avg_percentage_saved_with_context": 4.242959074495373,
            "avg_percentage_saved_without_context": 6.08247309609656,
            "early_stopping_rate_with_context": 12.0,
            "early_stopping_rate_without_context": 14.000000000000002,
            "accuracy_dropped_with_context": 4.0,
            "abstention_increased_without_context": 12.0
          }
        }
      },
      {
        "size": "32B",
        "rl_tuned": true,
        "family": "Qwen",
        "model_name": "Qwen/QwQ-32B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 164.46212121212122,
            "avg_tokens_saved_without_context": 2414.0530303030305,
            "avg_percentage_saved_with_context": 2.4587547521238364,
            "avg_percentage_saved_without_context": 49.74062158421744,
            "early_stopping_rate_with_context": 6.0606060606060606,
            "early_stopping_rate_without_context": 89.39393939393939,
            "accuracy_dropped_with_context": 5.303030303030303,
            "abstention_increased_without_context": 28.78787878787879
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 98.43283582089552,
            "avg_tokens_saved_without_context": 4389.522388059701,
            "avg_percentage_saved_with_context": 2.253280876781075,
            "avg_percentage_saved_without_context": 53.551739737374085,
            "early_stopping_rate_with_context": 5.970149253731343,
            "early_stopping_rate_without_context": 79.1044776119403,
            "accuracy_dropped_with_context": 5.970149253731343,
            "abstention_increased_without_context": 44.776119402985074
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 266.95,
            "avg_tokens_saved_without_context": 1143.2,
            "avg_percentage_saved_with_context": 3.903348442754789,
            "avg_percentage_saved_without_context": 24.085116049724466,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 45.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 15.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 54.98550724637681,
            "avg_tokens_saved_without_context": 81.76811594202898,
            "avg_percentage_saved_with_context": 1.9019085760204968,
            "avg_percentage_saved_without_context": 3.0903613208721366,
            "early_stopping_rate_with_context": 5.797101449275362,
            "early_stopping_rate_without_context": 10.144927536231885,
            "accuracy_dropped_with_context": 2.898550724637681,
            "abstention_increased_without_context": 10.144927536231885
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 48.96,
            "avg_tokens_saved_without_context": 297.34,
            "avg_percentage_saved_with_context": 0.9241354729216724,
            "avg_percentage_saved_without_context": 6.627757953843603,
            "early_stopping_rate_with_context": 3.0,
            "early_stopping_rate_without_context": 12.0,
            "accuracy_dropped_with_context": 3.0,
            "abstention_increased_without_context": 10.0
          }
        }
      },
      {
        "size": "32B",
        "rl_tuned": true,
        "family": "Qwen",
        "model_name": "Qwen/Qwen3-32B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 49.3,
            "avg_tokens_saved_without_context": 857.97,
            "avg_percentage_saved_with_context": 0.9401559287885151,
            "avg_percentage_saved_without_context": 25.41336195089121,
            "early_stopping_rate_with_context": 3.0,
            "early_stopping_rate_without_context": 66.0,
            "accuracy_dropped_with_context": 2.0,
            "abstention_increased_without_context": 5.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 67.53731343283582,
            "avg_tokens_saved_without_context": 2551.373134328358,
            "avg_percentage_saved_with_context": 1.388693102386133,
            "avg_percentage_saved_without_context": 40.38128264599979,
            "early_stopping_rate_with_context": 4.477611940298507,
            "early_stopping_rate_without_context": 62.68656716417911,
            "accuracy_dropped_with_context": 4.477611940298507,
            "abstention_increased_without_context": 14.925373134328357
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 508.55,
            "avg_tokens_saved_without_context": 2059.35,
            "avg_percentage_saved_with_context": 7.707933390840014,
            "avg_percentage_saved_without_context": 32.81854489362265,
            "early_stopping_rate_with_context": 10.0,
            "early_stopping_rate_without_context": 50.0,
            "accuracy_dropped_with_context": 5.0,
            "abstention_increased_without_context": 25.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 71.1304347826087,
            "avg_tokens_saved_without_context": 101.15942028985508,
            "avg_percentage_saved_with_context": 2.547595394569117,
            "avg_percentage_saved_without_context": 4.261059062096005,
            "early_stopping_rate_with_context": 7.246376811594203,
            "early_stopping_rate_without_context": 11.594202898550725,
            "accuracy_dropped_with_context": 4.3478260869565215,
            "abstention_increased_without_context": 10.144927536231885
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 30.89,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 1.175243102136718,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 4.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 2.0
          }
        }
      },
      {
        "size": "32B",
        "rl_tuned": true,
        "family": "Skywork",
        "model_name": "Skywork/Skywork-OR1-32B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 66.83,
            "avg_tokens_saved_without_context": 2720.33,
            "avg_percentage_saved_with_context": 1.348510514891757,
            "avg_percentage_saved_without_context": 52.225324846754276,
            "early_stopping_rate_with_context": 3.0,
            "early_stopping_rate_without_context": 86.0,
            "accuracy_dropped_with_context": 3.0,
            "abstention_increased_without_context": 28.999999999999996
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 723.7611940298508,
            "avg_tokens_saved_without_context": 3913.6119402985073,
            "avg_percentage_saved_with_context": 9.830665002730132,
            "avg_percentage_saved_without_context": 46.003711913384414,
            "early_stopping_rate_with_context": 16.417910447761194,
            "early_stopping_rate_without_context": 59.70149253731343,
            "accuracy_dropped_with_context": 16.417910447761194,
            "abstention_increased_without_context": 40.298507462686565
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 302.95,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 6.308863236891859,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 10.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 10.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 58.130434782608695,
            "avg_tokens_saved_without_context": 177.66666666666666,
            "avg_percentage_saved_with_context": 2.2559636354028756,
            "avg_percentage_saved_without_context": 5.391258156746899,
            "early_stopping_rate_with_context": 5.797101449275362,
            "early_stopping_rate_without_context": 21.73913043478261,
            "accuracy_dropped_with_context": 2.898550724637681,
            "abstention_increased_without_context": 21.73913043478261
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 44.01,
            "avg_tokens_saved_without_context": 421.67,
            "avg_percentage_saved_with_context": 1.417038882639949,
            "avg_percentage_saved_without_context": 4.369789345476215,
            "early_stopping_rate_with_context": 3.0,
            "early_stopping_rate_without_context": 10.0,
            "accuracy_dropped_with_context": 2.0,
            "abstention_increased_without_context": 9.0
          }
        }
      }
    ],
    "averages": {
      "gsm8k": {
        "avg_tokens_saved_with_context": 166.97301346801345,
        "avg_tokens_saved_without_context": 3005.5342255892256,
        "avg_percentage_saved_with_context": 2.4007338612451847,
        "avg_percentage_saved_without_context": 49.687546484835345,
        "early_stopping_rate_with_context": 4.506734006734007,
        "early_stopping_rate_without_context": 85.0993265993266,
        "accuracy_dropped_with_context": 3.755892255892256,
        "abstention_increased_without_context": 29.14309764309764
      },
      "mmlu": {
        "avg_tokens_saved_with_context": 247.98673300165834,
        "avg_tokens_saved_without_context": 5213.4626865671635,
        "avg_percentage_saved_with_context": 3.425147394573431,
        "avg_percentage_saved_without_context": 56.15603294441399,
        "early_stopping_rate_with_context": 6.301824212271973,
        "early_stopping_rate_without_context": 77.28026533996683,
        "accuracy_dropped_with_context": 6.135986733001658,
        "abstention_increased_without_context": 44.61028192371476
      },
      "gpqa": {
        "avg_tokens_saved_with_context": 1181.263888888889,
        "avg_tokens_saved_without_context": 2694.608333333333,
        "avg_percentage_saved_with_context": 9.548020772277276,
        "avg_percentage_saved_without_context": 27.10709510215631,
        "early_stopping_rate_with_context": 11.944444444444445,
        "early_stopping_rate_without_context": 39.166666666666664,
        "accuracy_dropped_with_context": 3.3333333333333335,
        "abstention_increased_without_context": 26.11111111111111
      },
      "icraft": {
        "avg_tokens_saved_with_context": 148.98711755233495,
        "avg_tokens_saved_without_context": 300.0966183574879,
        "avg_percentage_saved_with_context": 3.480713548035125,
        "avg_percentage_saved_without_context": 6.517758272629627,
        "early_stopping_rate_with_context": 7.568438003220613,
        "early_stopping_rate_without_context": 14.170692431561996,
        "accuracy_dropped_with_context": 3.864734299516909,
        "abstention_increased_without_context": 13.204508856682772
      },
      "imedqa": {
        "avg_tokens_saved_with_context": 245.54333333333338,
        "avg_tokens_saved_without_context": 592.0344444444445,
        "avg_percentage_saved_with_context": 3.9405368795375875,
        "avg_percentage_saved_without_context": 8.930891380638462,
        "early_stopping_rate_with_context": 7.333333333333333,
        "early_stopping_rate_without_context": 16.666666666666668,
        "accuracy_dropped_with_context": 3.4444444444444446,
        "abstention_increased_without_context": 14.555555555555555
      }
    }
  },
  "Distilled Models": {
    "models": [
      {
        "size": "0.6B",
        "rl_tuned": false,
        "family": "Qwen",
        "model_name": "Qwen/Qwen3-0.6B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 364.14,
            "avg_tokens_saved_without_context": 409.19,
            "avg_percentage_saved_with_context": 7.951199523549827,
            "avg_percentage_saved_without_context": 14.561070558069877,
            "early_stopping_rate_with_context": 15.0,
            "early_stopping_rate_without_context": 43.0,
            "accuracy_dropped_with_context": 5.0,
            "abstention_increased_without_context": 0.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 1108.7014925373135,
            "avg_tokens_saved_without_context": 2149.179104477612,
            "avg_percentage_saved_with_context": 10.989172912991124,
            "avg_percentage_saved_without_context": 38.9531260613475,
            "early_stopping_rate_with_context": 16.417910447761194,
            "early_stopping_rate_without_context": 74.6268656716418,
            "accuracy_dropped_with_context": 8.955223880597014,
            "abstention_increased_without_context": 17.91044776119403
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 89.9,
            "avg_tokens_saved_without_context": 372.15,
            "avg_percentage_saved_with_context": 3.4763455207321146,
            "avg_percentage_saved_without_context": 8.472826611937055,
            "early_stopping_rate_with_context": 10.0,
            "early_stopping_rate_without_context": 15.0,
            "accuracy_dropped_with_context": 5.0,
            "abstention_increased_without_context": 5.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 0.0,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 0.0,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 0.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 0.0
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 15.73,
            "avg_tokens_saved_without_context": 0.0,
            "avg_percentage_saved_with_context": 0.6895862785406792,
            "avg_percentage_saved_without_context": 0.0,
            "early_stopping_rate_with_context": 2.0,
            "early_stopping_rate_without_context": 0.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 0.0
          }
        }
      },
      {
        "size": "1.5B",
        "rl_tuned": false,
        "family": "DeepSeek",
        "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 165.96,
            "avg_tokens_saved_without_context": 898.76,
            "avg_percentage_saved_with_context": 3.3740462348054168,
            "avg_percentage_saved_without_context": 22.114703789700165,
            "early_stopping_rate_with_context": 8.0,
            "early_stopping_rate_without_context": 42.0,
            "accuracy_dropped_with_context": 4.0,
            "abstention_increased_without_context": 17.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 246.7910447761194,
            "avg_tokens_saved_without_context": 2708.8507462686566,
            "avg_percentage_saved_with_context": 4.8405364644085545,
            "avg_percentage_saved_without_context": 44.3060039185276,
            "early_stopping_rate_with_context": 8.955223880597014,
            "early_stopping_rate_without_context": 68.65671641791045,
            "accuracy_dropped_with_context": 5.970149253731343,
            "abstention_increased_without_context": 50.74626865671642
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 96.3,
            "avg_tokens_saved_without_context": 440.4,
            "avg_percentage_saved_with_context": 2.810858143607706,
            "avg_percentage_saved_without_context": 11.308924792972922,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 25.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 20.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 9.391304347826088,
            "avg_tokens_saved_without_context": 9.043478260869565,
            "avg_percentage_saved_with_context": 0.5106186108769618,
            "avg_percentage_saved_without_context": 0.6005563640400579,
            "early_stopping_rate_with_context": 2.898550724637681,
            "early_stopping_rate_without_context": 2.898550724637681,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 2.898550724637681
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 6.84,
            "avg_tokens_saved_without_context": 0.66,
            "avg_percentage_saved_with_context": 0.29947460595446584,
            "avg_percentage_saved_without_context": 0.045020463847203276,
            "early_stopping_rate_with_context": 1.0,
            "early_stopping_rate_without_context": 1.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 1.0
          }
        }
      },
      {
        "size": "1.7B",
        "rl_tuned": false,
        "family": "Qwen",
        "model_name": "Qwen/Qwen3-1.7B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 75.86,
            "avg_tokens_saved_without_context": 638.17,
            "avg_percentage_saved_with_context": 2.4228324042637825,
            "avg_percentage_saved_without_context": 23.22263019857751,
            "early_stopping_rate_with_context": 6.0,
            "early_stopping_rate_without_context": 68.0,
            "accuracy_dropped_with_context": 5.0,
            "abstention_increased_without_context": 1.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 90.02985074626865,
            "avg_tokens_saved_without_context": 2413.3432835820895,
            "avg_percentage_saved_with_context": 2.1698296033590116,
            "avg_percentage_saved_without_context": 44.031553348796194,
            "early_stopping_rate_with_context": 4.477611940298507,
            "early_stopping_rate_without_context": 74.6268656716418,
            "accuracy_dropped_with_context": 2.9850746268656714,
            "abstention_increased_without_context": 11.940298507462686
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 459.4,
            "avg_tokens_saved_without_context": 460.8,
            "avg_percentage_saved_with_context": 7.537317878110409,
            "avg_percentage_saved_without_context": 11.270596799653536,
            "early_stopping_rate_with_context": 10.0,
            "early_stopping_rate_without_context": 20.0,
            "accuracy_dropped_with_context": 5.0,
            "abstention_increased_without_context": 0.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 29.420289855072465,
            "avg_tokens_saved_without_context": 66.6086956521739,
            "avg_percentage_saved_with_context": 1.265071901357612,
            "avg_percentage_saved_without_context": 3.0190170057349888,
            "early_stopping_rate_with_context": 4.3478260869565215,
            "early_stopping_rate_without_context": 10.144927536231885,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 10.144927536231885
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 101.19,
            "avg_tokens_saved_without_context": 86.58,
            "avg_percentage_saved_with_context": 3.2403087634666137,
            "avg_percentage_saved_without_context": 3.9988793246187067,
            "early_stopping_rate_with_context": 8.0,
            "early_stopping_rate_without_context": 14.000000000000002,
            "accuracy_dropped_with_context": 3.0,
            "abstention_increased_without_context": 10.0
          }
        }
      },
      {
        "size": "4B",
        "rl_tuned": false,
        "family": "Phi",
        "model_name": "microsoft/Phi-4-mini-reasoning",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 10.47,
            "avg_tokens_saved_without_context": 997.91,
            "avg_percentage_saved_with_context": 0.42787086228034327,
            "avg_percentage_saved_without_context": 32.19217590763384,
            "early_stopping_rate_with_context": 1.0,
            "early_stopping_rate_without_context": 76.0,
            "accuracy_dropped_with_context": 1.0,
            "abstention_increased_without_context": 13.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 105.40298507462687,
            "avg_tokens_saved_without_context": 2348.268656716418,
            "avg_percentage_saved_with_context": 2.0452254404535166,
            "avg_percentage_saved_without_context": 40.548012300653674,
            "early_stopping_rate_with_context": 4.477611940298507,
            "early_stopping_rate_without_context": 74.6268656716418,
            "accuracy_dropped_with_context": 4.477611940298507,
            "abstention_increased_without_context": 29.850746268656714
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 1061.05,
            "avg_tokens_saved_without_context": 3075.0,
            "avg_percentage_saved_with_context": 13.602723482588766,
            "avg_percentage_saved_without_context": 52.11608394534087,
            "early_stopping_rate_with_context": 20.0,
            "early_stopping_rate_without_context": 80.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 40.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 78.52173913043478,
            "avg_tokens_saved_without_context": 130.2173913043478,
            "avg_percentage_saved_with_context": 2.274096024187319,
            "avg_percentage_saved_without_context": 4.322295663680581,
            "early_stopping_rate_with_context": 5.797101449275362,
            "early_stopping_rate_without_context": 13.043478260869565,
            "accuracy_dropped_with_context": 1.4492753623188406,
            "abstention_increased_without_context": 13.043478260869565
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 234.83,
            "avg_tokens_saved_without_context": 106.0,
            "avg_percentage_saved_with_context": 5.3422691481363564,
            "avg_percentage_saved_without_context": 3.8622365539079886,
            "early_stopping_rate_with_context": 11.0,
            "early_stopping_rate_without_context": 11.0,
            "accuracy_dropped_with_context": 9.0,
            "abstention_increased_without_context": 6.0
          }
        }
      },
      {
        "size": "4B",
        "rl_tuned": false,
        "family": "Phi",
        "model_name": "microsoft/Phi-4-mini-flash-reasoning",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 39.4,
            "avg_tokens_saved_without_context": 1191.46,
            "avg_percentage_saved_with_context": 1.48069701820133,
            "avg_percentage_saved_without_context": 33.89882048413023,
            "early_stopping_rate_with_context": 3.0,
            "early_stopping_rate_without_context": 74.0,
            "accuracy_dropped_with_context": 2.0,
            "abstention_increased_without_context": 11.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 87.11940298507463,
            "avg_tokens_saved_without_context": 3895.089552238806,
            "avg_percentage_saved_with_context": 1.7138879789623493,
            "avg_percentage_saved_without_context": 49.278252817870985,
            "early_stopping_rate_with_context": 2.9850746268656714,
            "early_stopping_rate_without_context": 73.13432835820896,
            "accuracy_dropped_with_context": 2.9850746268656714,
            "abstention_increased_without_context": 26.865671641791046
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 1106.15,
            "avg_tokens_saved_without_context": 1833.1,
            "avg_percentage_saved_with_context": 16.408247618628575,
            "avg_percentage_saved_without_context": 32.4237757898038,
            "early_stopping_rate_with_context": 25.0,
            "early_stopping_rate_without_context": 55.00000000000001,
            "accuracy_dropped_with_context": 5.0,
            "abstention_increased_without_context": 30.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 73.7536231884058,
            "avg_tokens_saved_without_context": 318.39130434782606,
            "avg_percentage_saved_with_context": 1.9723366798829074,
            "avg_percentage_saved_without_context": 8.857214117546977,
            "early_stopping_rate_with_context": 4.3478260869565215,
            "early_stopping_rate_without_context": 23.18840579710145,
            "accuracy_dropped_with_context": 2.898550724637681,
            "abstention_increased_without_context": 21.73913043478261
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 104.68,
            "avg_tokens_saved_without_context": 484.97,
            "avg_percentage_saved_with_context": 2.196359302269768,
            "avg_percentage_saved_without_context": 9.583003420501006,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 20.0,
            "accuracy_dropped_with_context": 1.0,
            "abstention_increased_without_context": 17.0
          }
        }
      },
      {
        "size": "7B",
        "rl_tuned": false,
        "family": "DeepSeek",
        "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 112.03,
            "avg_tokens_saved_without_context": 345.77,
            "avg_percentage_saved_with_context": 1.5779761875755713,
            "avg_percentage_saved_without_context": 8.533982745351546,
            "early_stopping_rate_with_context": 3.0,
            "early_stopping_rate_without_context": 16.0,
            "accuracy_dropped_with_context": 2.0,
            "abstention_increased_without_context": 4.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 18.059701492537314,
            "avg_tokens_saved_without_context": 2491.731343283582,
            "avg_percentage_saved_with_context": 0.6664096491711186,
            "avg_percentage_saved_without_context": 46.517762271222644,
            "early_stopping_rate_with_context": 1.4925373134328357,
            "early_stopping_rate_without_context": 77.61194029850746,
            "accuracy_dropped_with_context": 1.4925373134328357,
            "abstention_increased_without_context": 49.25373134328358
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 104.25,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 2.907949790794979,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 5.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 5.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 38.26086956521739,
            "avg_tokens_saved_without_context": 4.202898550724638,
            "avg_percentage_saved_with_context": 1.6562655954949261,
            "avg_percentage_saved_without_context": 0.18353268780456933,
            "early_stopping_rate_with_context": 8.695652173913043,
            "early_stopping_rate_without_context": 1.4492753623188406,
            "accuracy_dropped_with_context": 2.898550724637681,
            "abstention_increased_without_context": 1.4492753623188406
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 68.8,
            "avg_tokens_saved_without_context": 13.9,
            "avg_percentage_saved_with_context": 2.2309063472304613,
            "avg_percentage_saved_without_context": 0.623589951186826,
            "early_stopping_rate_with_context": 7.000000000000001,
            "early_stopping_rate_without_context": 3.0,
            "accuracy_dropped_with_context": 2.0,
            "abstention_increased_without_context": 2.0
          }
        }
      },
      {
        "size": "8B",
        "rl_tuned": false,
        "family": "DeepSeek",
        "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 174.87,
            "avg_tokens_saved_without_context": 566.55,
            "avg_percentage_saved_with_context": 2.735549683017398,
            "avg_percentage_saved_without_context": 13.310321574032203,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 27.0,
            "accuracy_dropped_with_context": 4.0,
            "abstention_increased_without_context": 7.000000000000001
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 307.55223880597015,
            "avg_tokens_saved_without_context": 2425.492537313433,
            "avg_percentage_saved_with_context": 5.59575777873051,
            "avg_percentage_saved_without_context": 40.50955572250112,
            "early_stopping_rate_with_context": 11.940298507462686,
            "early_stopping_rate_without_context": 65.67164179104478,
            "accuracy_dropped_with_context": 10.44776119402985,
            "abstention_increased_without_context": 49.25373134328358
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 29.15,
            "avg_tokens_saved_without_context": 269.85,
            "avg_percentage_saved_with_context": 0.4002471508993547,
            "avg_percentage_saved_without_context": 7.4445672830407945,
            "early_stopping_rate_with_context": 5.0,
            "early_stopping_rate_without_context": 15.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 15.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 15.927536231884059,
            "avg_tokens_saved_without_context": 1.289855072463768,
            "avg_percentage_saved_with_context": 0.5901273150012619,
            "avg_percentage_saved_without_context": 0.09286213624649158,
            "early_stopping_rate_with_context": 1.4492753623188406,
            "early_stopping_rate_without_context": 1.4492753623188406,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 1.4492753623188406
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 0.0,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 0.0,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 0.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 0.0
          }
        }
      },
      {
        "size": "8B",
        "rl_tuned": false,
        "family": "Qwen",
        "model_name": "Qwen/Qwen3-8B",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 249.08,
            "avg_tokens_saved_without_context": 1017.77,
            "avg_percentage_saved_with_context": 4.986300238493179,
            "avg_percentage_saved_without_context": 29.980821911599087,
            "early_stopping_rate_with_context": 10.0,
            "early_stopping_rate_without_context": 71.0,
            "accuracy_dropped_with_context": 10.0,
            "abstention_increased_without_context": 1.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 113.50746268656717,
            "avg_tokens_saved_without_context": 2597.10447761194,
            "avg_percentage_saved_with_context": 3.1413182207637034,
            "avg_percentage_saved_without_context": 41.3194635502678,
            "early_stopping_rate_with_context": 7.462686567164178,
            "early_stopping_rate_without_context": 64.17910447761194,
            "accuracy_dropped_with_context": 7.462686567164178,
            "abstention_increased_without_context": 13.432835820895523
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 653.1,
            "avg_tokens_saved_without_context": 429.25,
            "avg_percentage_saved_with_context": 8.1248537043656,
            "avg_percentage_saved_without_context": 13.142379524452224,
            "early_stopping_rate_with_context": 10.0,
            "early_stopping_rate_without_context": 25.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 10.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 0.0,
            "avg_tokens_saved_without_context": 12.55072463768116,
            "avg_percentage_saved_with_context": 0.0,
            "avg_percentage_saved_without_context": 0.7447395347308293,
            "early_stopping_rate_with_context": 0.0,
            "early_stopping_rate_without_context": 4.3478260869565215,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 4.3478260869565215
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 27.63,
            "avg_tokens_saved_without_context": 82.02,
            "avg_percentage_saved_with_context": 1.1925780550029474,
            "avg_percentage_saved_without_context": 2.599820384789245,
            "early_stopping_rate_with_context": 4.0,
            "early_stopping_rate_without_context": 9.0,
            "accuracy_dropped_with_context": 2.0,
            "abstention_increased_without_context": 5.0
          }
        }
      },
      {
        "size": "14B",
        "rl_tuned": false,
        "family": "Phi",
        "model_name": "microsoft/Phi-4-reasoning",
        "metrics": {
          "gsm8k": {
            "avg_tokens_saved_with_context": 24.26,
            "avg_tokens_saved_without_context": 1870.31,
            "avg_percentage_saved_with_context": 0.8266109238180629,
            "avg_percentage_saved_without_context": 41.03786875233777,
            "early_stopping_rate_with_context": 2.0,
            "early_stopping_rate_without_context": 83.0,
            "accuracy_dropped_with_context": 1.0,
            "abstention_increased_without_context": 34.0
          },
          "mmlu": {
            "avg_tokens_saved_with_context": 147.34328358208955,
            "avg_tokens_saved_without_context": 3640.6417910447763,
            "avg_percentage_saved_with_context": 2.4207691294970215,
            "avg_percentage_saved_without_context": 40.07749395786348,
            "early_stopping_rate_with_context": 4.477611940298507,
            "early_stopping_rate_without_context": 71.64179104477611,
            "accuracy_dropped_with_context": 1.4925373134328357,
            "abstention_increased_without_context": 29.850746268656714
          },
          "gpqa": {
            "avg_tokens_saved_with_context": 1286.25,
            "avg_tokens_saved_without_context": 3131.9,
            "avg_percentage_saved_with_context": 10.14762188659319,
            "avg_percentage_saved_without_context": 45.94606836922575,
            "early_stopping_rate_with_context": 20.0,
            "early_stopping_rate_without_context": 75.0,
            "accuracy_dropped_with_context": 0.0,
            "abstention_increased_without_context": 45.0
          },
          "icraft": {
            "avg_tokens_saved_with_context": 205.52173913043478,
            "avg_tokens_saved_without_context": 213.7391304347826,
            "avg_percentage_saved_with_context": 5.50886268175157,
            "avg_percentage_saved_without_context": 7.185015841723341,
            "early_stopping_rate_with_context": 13.043478260869565,
            "early_stopping_rate_without_context": 15.942028985507244,
            "accuracy_dropped_with_context": 10.144927536231885,
            "abstention_increased_without_context": 14.492753623188406
          },
          "imedqa": {
            "avg_tokens_saved_with_context": 326.12,
            "avg_tokens_saved_without_context": 544.61,
            "avg_percentage_saved_with_context": 7.524147293249866,
            "avg_percentage_saved_without_context": 13.955385310090657,
            "early_stopping_rate_with_context": 15.0,
            "early_stopping_rate_without_context": 31.0,
            "accuracy_dropped_with_context": 11.0,
            "abstention_increased_without_context": 27.0
          }
        }
      }
    ],
    "averages": {
      "gsm8k": {
        "avg_tokens_saved_with_context": 135.1188888888889,
        "avg_tokens_saved_without_context": 881.7655555555556,
        "avg_percentage_saved_with_context": 2.8647870084449902,
        "avg_percentage_saved_without_context": 24.316932880159136,
        "early_stopping_rate_with_context": 5.888888888888889,
        "early_stopping_rate_without_context": 55.55555555555556,
        "accuracy_dropped_with_context": 3.7777777777777777,
        "abstention_increased_without_context": 9.777777777777779
      },
      "mmlu": {
        "avg_tokens_saved_with_context": 247.16749585406296,
        "avg_tokens_saved_without_context": 2741.077943615257,
        "avg_percentage_saved_with_context": 3.7314341309263233,
        "avg_percentage_saved_without_context": 42.83791377211678,
        "early_stopping_rate_with_context": 6.965174129353234,
        "early_stopping_rate_without_context": 71.6417910447761,
        "accuracy_dropped_with_context": 5.140961857379768,
        "abstention_increased_without_context": 31.011608623548923
      },
      "gpqa": {
        "avg_tokens_saved_with_context": 531.2555555555555,
        "avg_tokens_saved_without_context": 1124.0777777777778,
        "avg_percentage_saved_with_context": 6.945357265058413,
        "avg_percentage_saved_without_context": 20.559241434135767,
        "early_stopping_rate_with_context": 11.666666666666666,
        "early_stopping_rate_without_context": 35.0,
        "accuracy_dropped_with_context": 1.6666666666666667,
        "abstention_increased_without_context": 18.88888888888889
      },
      "icraft": {
        "avg_tokens_saved_with_context": 50.08856682769726,
        "avg_tokens_saved_without_context": 84.00483091787439,
        "avg_percentage_saved_with_context": 1.5308198676169509,
        "avg_percentage_saved_without_context": 2.7783592612786485,
        "early_stopping_rate_with_context": 4.508856682769726,
        "early_stopping_rate_without_context": 8.051529790660224,
        "accuracy_dropped_with_context": 1.932367149758454,
        "abstention_increased_without_context": 7.729468599033816
      },
      "imedqa": {
        "avg_tokens_saved_with_context": 98.42444444444443,
        "avg_tokens_saved_without_context": 146.52666666666667,
        "avg_percentage_saved_with_context": 2.5239588659834618,
        "avg_percentage_saved_without_context": 3.8519928232157365,
        "early_stopping_rate_with_context": 5.888888888888889,
        "early_stopping_rate_without_context": 9.88888888888889,
        "accuracy_dropped_with_context": 3.111111111111111,
        "abstention_increased_without_context": 7.555555555555555
      }
    }
  }
}